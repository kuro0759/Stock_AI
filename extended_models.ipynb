{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拡張時系列モデル評価\n",
    "複数のモデルを試し、途中経過を表示しながら精度を比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# データ取得と前処理\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# pip install yfinance numpy pandas scikit-learn xgboost lightgbm catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 0. データ取得・前処理\n",
    "# ------------------------------------------------------------\n",
    "# 2018–2023年の米国3大IT銘柄を例にダウンロード\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOG\"]\n",
    "df = yf.download(\n",
    "    tickers,\n",
    "    start=\"2018-01-01\",\n",
    "    end=\"2023-12-31\",\n",
    "    interval=\"1d\",\n",
    "    auto_adjust=True\n",
    ")\n",
    "\n",
    "# 欲しい列をリネームして結合\n",
    "price = df[\"Close\"].rename(columns=lambda c: f\"{c}_Close\")\n",
    "vol   = df[\"Volume\"].rename(columns=lambda c: f\"{c}_Volume\")\n",
    "data  = pd.concat([price, vol], axis=1).dropna()\n",
    "\n",
    "# テクニカル指標：5日移動平均とRSIを追加\n",
    "for t in tickers:\n",
    "    data[f\"{t}_MA5\"] = data[f\"{t}_Close\"].rolling(window=5).mean()\n",
    "    delta = data[f\"{t}_Close\"].diff()\n",
    "    up, down = delta.clip(lower=0), -delta.clip(upper=0)\n",
    "    rs = up.rolling(14).mean() / down.rolling(14).mean()\n",
    "    data[f\"{t}_RSI\"] = 100 - 100 / (1 + rs)\n",
    "\n",
    "# 目的変数：AAPL の翌日リターンを計算し、正負をラベル化\n",
    "data[\"Return\"] = data[\"AAPL_Close\"].pct_change().shift(-1)\n",
    "data = data.dropna()\n",
    "data[\"Label\"] = (data[\"Return\"] > 0).astype(int)\n",
    "\n",
    "# 説明変数・ラベルを取得\n",
    "feature_cols = [c for c in data.columns if c not in [\"Return\", \"Label\"]]\n",
    "X = data[feature_cols].values\n",
    "y = data[\"Label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1. 学習/テスト分割とスケーリング\n",
    "# ------------------------------------------------------------\n",
    "# 時系列保持で 80% 学習、20% テスト\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_tr, X_te = X[:split_idx], X[split_idx:]\n",
    "y_tr, y_te = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# 標準化\n",
    "scaler      = StandardScaler()\n",
    "X_tr_scaled = scaler.fit_transform(X_tr)\n",
    "X_te_scaled = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 2. 不均衡対応の重み計算\n",
    "# ------------------------------------------------------------\n",
    "pos_weight = (y_tr == 0).sum() / (y_tr == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 3. 学習用と検証用にさらに分割（early stopping 用）\n",
    "# ------------------------------------------------------------\n",
    "X_train_part, X_val, y_train_part, y_val = train_test_split(\n",
    "    X_tr_scaled, y_tr, test_size=0.2, shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4. モデルリスト＆ハイパーパラメータ空間\n",
    "# ------------------------------------------------------------\n",
    "models = [\n",
    "    (\"LogisticRegression\",\n",
    "        LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
    "        {\"C\": [0.1, 1, 10]}),\n",
    "    (\"XGBoost\",\n",
    "        XGBClassifier(\n",
    "            random_state=42,\n",
    "            scale_pos_weight=pos_weight,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\"\n",
    "        ),\n",
    "        {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}),\n",
    "    (\"LightGBM\",\n",
    "        LGBMClassifier(random_state=42, is_unbalance=True),\n",
    "        {\"n_estimators\": [100, 200], \"num_leaves\": [31, 63]}),\n",
    "    (\"CatBoost\",\n",
    "        CatBoostClassifier(random_state=42, verbose=0),\n",
    "        {\"depth\": [4, 6], \"learning_rate\": [0.03, 0.1]})\n",
    "]\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ LogisticRegression のランダムサーチを開始…\n",
      "  ベストパラメータ: {'C': 0.1}\n",
      "  Test Accuracy: 0.525 / AUC: 0.549\n",
      "\n",
      "▶️ XGBoost のランダムサーチを開始…\n",
      "  ベストパラメータ: {'n_estimators': 200, 'max_depth': 3}\n",
      "  Test Accuracy: 0.528 / AUC: 0.523\n",
      "\n",
      "▶️ LightGBM のランダムサーチを開始…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"c:\\Users\\T123011\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 247, in _count_physical_cores\n",
      "    cpu_count_physical = _count_physical_cores_win32()\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\T123011\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 299, in _count_physical_cores_win32\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\T123011\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\T123011\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\T123011\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 517, number of negative: 439\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 956, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.540795 -> initscore=0.163543\n",
      "[LightGBM] [Info] Start training from score 0.163543\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "  ベストパラメータ: {'num_leaves': 63, 'n_estimators': 100}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LGBMClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m         best.fit(X_train_part, y_train_part,\n\u001b[32m     35\u001b[39m                  eval_set=[(X_val, y_val)], verbose=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mLightGBM\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[43mbest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_train_part\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_part\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mCatBoost\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     44\u001b[39m     best.fit(\n\u001b[32m     45\u001b[39m         X_train_part, y_train_part,\n\u001b[32m     46\u001b[39m         eval_set=[(X_val, y_val)],\n\u001b[32m     47\u001b[39m         verbose=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     48\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: LGBMClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 5. 各モデルのチューニング＆再学習＆評価ループ\n",
    "# ------------------------------------------------------------\n",
    "results = []\n",
    "for name, base_model, param_dist in models:\n",
    "    print(f\"\\n▶️ {name} のランダムサーチを開始…\")\n",
    "    search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=2,\n",
    "        cv=TimeSeriesSplit(n_splits=3),\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    search.fit(X_train_part, y_train_part)\n",
    "    best = search.best_estimator_\n",
    "    print(\"  ベストパラメータ:\", search.best_params_)\n",
    "\n",
    "    # ✔️ 最良モデルを再学習（early stopping を使いたい場合は以下のように）\n",
    "    if name == \"XGBoost\":\n",
    "        try:\n",
    "            best.fit(\n",
    "                X_train_part, y_train_part,\n",
    "                eval_set=[(X_val, y_val)],\n",
    "                early_stopping_rounds=20,\n",
    "                verbose=False\n",
    "            )\n",
    "        except TypeError:\n",
    "            # 古い xgboost では early_stopping_rounds をコンストラクタに渡す必要があるかも\n",
    "            best = XGBClassifier(**search.best_params_, random_state=42,\n",
    "                                 eval_metric=\"logloss\", use_label_encoder=False,\n",
    "                                 early_stopping_rounds=20)\n",
    "            best.fit(X_train_part, y_train_part,\n",
    "                     eval_set=[(X_val, y_val)], verbose=False)\n",
  "    elif name == \"LightGBM\":\n",
  "        try:\n",
  "            best.fit(\n",
  "                X_train_part, y_train_part,\n",
  "                eval_set=[(X_val, y_val)],\n",
  "                early_stopping_rounds=20,\n",
  "                verbose=False\n",
  "            )\n",
  "        except TypeError:\n",
  "            best.fit(\n",
  "                X_train_part, y_train_part,\n",
  "                eval_set=[(X_val, y_val)],\n",
  "                callbacks=[lgb.early_stopping(stopping_rounds=20)],\n",
  "                verbose=False\n",
  "            )\n",
    "    elif name == \"CatBoost\":\n",
    "        best.fit(\n",
    "            X_train_part, y_train_part,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "    else:\n",
    "        # LogisticRegression のように early stopping を持たないモデル\n",
    "        best.fit(X_train_part, y_train_part)\n",
    "\n",
    "    # テストデータで予測＆評価\n",
    "    y_pred = best.predict(X_te_scaled)\n",
    "    acc    = accuracy_score(y_te, y_pred)\n",
    "\n",
    "    # AUC を計算できるモデルだけ try/except で包む\n",
    "    try:\n",
    "        proba = best.predict_proba(X_te_scaled)[:, 1]\n",
    "        auc   = roc_auc_score(y_te, proba)\n",
    "    except Exception:\n",
    "        auc = np.nan\n",
    "\n",
    "    print(f\"  Test Accuracy: {acc:.3f} / AUC: {auc:.3f}\")\n",
    "    results.append({\"Model\": name, \"Accuracy\": acc, \"AUC\": auc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 6. 結果出力\n",
    "# ------------------------------------------------------------\n",
    "df_res = pd.DataFrame(results).set_index(\"Model\")\n",
    "print(\"\\n=== モデル比較結果 ===\")\n",
    "print(df_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
